{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-11T13:04:18.445977Z",
     "iopub.status.busy": "2025-11-11T13:04:18.445678Z",
     "iopub.status.idle": "2025-11-11T13:30:28.026725Z",
     "shell.execute_reply": "2025-11-11T13:30:28.025556Z",
     "shell.execute_reply.started": "2025-11-11T13:04:18.445957Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Labels: {'anxiety': 0, 'bipolar': 1, 'depression': 2, 'normal': 3, 'personality disorder': 4, 'stress': 5, 'suicidal': 6}\n",
      "üìä Dataset size: 52681\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c8d1c0f64147e2b3e90968f7888add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44778 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc814b414cd747b39b1187855d83df3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7903 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öñÔ∏è Class Weights: [0.8456476330757141, 1.1699321269989014, 0.21087905764579773, 0.1987646520137787, 3.014235496520996, 1.2555887699127197, 0.304952472448349]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5600' max='5600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5600/5600 25:27, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.598715</td>\n",
       "      <td>0.764773</td>\n",
       "      <td>0.742266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.489800</td>\n",
       "      <td>0.533104</td>\n",
       "      <td>0.811211</td>\n",
       "      <td>0.790274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.347500</td>\n",
       "      <td>0.549305</td>\n",
       "      <td>0.812603</td>\n",
       "      <td>0.798602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.255300</td>\n",
       "      <td>0.548064</td>\n",
       "      <td>0.823864</td>\n",
       "      <td>0.810938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Classification Report:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             anxiety       0.87      0.88      0.87       576\n",
      "             bipolar       0.83      0.88      0.86       417\n",
      "          depression       0.81      0.72      0.76      2311\n",
      "              normal       0.97      0.93      0.95      2452\n",
      "personality disorder       0.71      0.78      0.74       161\n",
      "              stress       0.71      0.84      0.77       388\n",
      "            suicidal       0.68      0.77      0.72      1598\n",
      "\n",
      "            accuracy                           0.82      7903\n",
      "           macro avg       0.80      0.83      0.81      7903\n",
      "        weighted avg       0.83      0.82      0.83      7903\n",
      "\n",
      "\n",
      "‚úÖ Model saved to: /kaggle/working/mentalwell_model_final\n",
      "üö® `do_pad` is part of DefaultFastImageProcessorKwargs, but not documented. Make sure to add it to the docstring of the function in /usr/local/lib/python3.11/dist-packages/transformers/image_processing_utils_fast.py.\n",
      "üö® `pad_size` is part of DefaultFastImageProcessorKwargs, but not documented. Make sure to add it to the docstring of the function in /usr/local/lib/python3.11/dist-packages/transformers/image_processing_utils_fast.py.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'make_batched_metadata' from 'transformers.video_utils' (/usr/local/lib/python3.11/dist-packages/transformers/video_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48/145110175.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;31m# üîü Test Prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;31m# ============================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text-classification\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_all_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2152\u001b[0m     \u001b[0mis_dummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2154\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"_from_config\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"is_dummy\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mro\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"call\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0mmodule_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2183\u001b[0m         \u001b[0mimport_structure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIMPORT_STRUCTURE_T\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2184\u001b[0;31m         \u001b[0mmodule_spec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmachinery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleSpec\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2185\u001b[0m         \u001b[0mextra_objects\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2186\u001b[0m         \u001b[0mexplicit_import_shortcut\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2180\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2181\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2182\u001b[0;31m         \u001b[0mmodule_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2183\u001b[0m         \u001b[0mimport_structure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIMPORT_STRUCTURE_T\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2184\u001b[0m         \u001b[0mmodule_spec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmachinery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleSpec\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_processing_auto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIMAGE_PROCESSOR_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoImageProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_auto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForDepthEstimation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForImageToImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessing_auto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPROCESSOR_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_auto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTOKENIZER_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProcessorMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/processing_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mtokenization_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFEATURE_EXTRACTOR_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPROCESSOR_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVIDEO_PROCESSOR_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mvideo_processing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseVideoProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mauto_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LazyAutoMapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m from .configuration_auto import (\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/video_processing_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequires\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m from .video_utils import (\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mVideoInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mVideoMetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'make_batched_metadata' from 'transformers.video_utils' (/usr/local/lib/python3.11/dist-packages/transformers/video_utils.py)"
     ]
    }
   ],
   "source": [
    "!pip install -q --upgrade transformers datasets accelerate scikit-learn torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "from torch import nn\n",
    "import os, warnings\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ============================================================\n",
    "# 1Ô∏è‚É£ Custom Weighted Trainer\n",
    "# ============================================================\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        \"\"\"\n",
    "        FINAL version:\n",
    "        - Handles num_items_in_batch\n",
    "        - Works with DataParallel or DDP\n",
    "        - Supports both 'labels' and 'label_id'\n",
    "        \"\"\"\n",
    "        # Extract labels safely\n",
    "        labels = inputs.pop(\"labels\", None)\n",
    "        if labels is None:\n",
    "            labels = inputs.pop(\"label_id\", None)\n",
    "\n",
    "        # Drop any unwanted Trainer args\n",
    "        for key in [\"num_items_in_batch\", \"loss_reduction\"]:\n",
    "            inputs.pop(key, None)\n",
    "            kwargs.pop(key, None)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        # ‚úÖ Handle both model and DataParallel wrapper\n",
    "        actual_model = model.module if hasattr(model, \"module\") else model\n",
    "\n",
    "        # ‚úÖ Correct device + config\n",
    "        device = next(model.parameters()).device\n",
    "        num_labels = actual_model.config.num_labels\n",
    "\n",
    "        # Weighted loss on correct device\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=weights.to(device))\n",
    "        loss = loss_fct(\n",
    "            logits.view(-1, num_labels),\n",
    "            labels.view(-1)\n",
    "        )\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2Ô∏è‚É£ Load and prepare dataset\n",
    "# ============================================================\n",
    "df = pd.read_csv(\"/kaggle/input/sentiment-analysis-for-mental-health/Combined Data.csv\")\n",
    "\n",
    "df = df.dropna(subset=[\"statement\", \"status\"])\n",
    "df[\"label\"] = df[\"status\"].str.lower().str.strip()\n",
    "\n",
    "labels = sorted(df[\"label\"].unique())\n",
    "label2id = {l: i for i, l in enumerate(labels)}\n",
    "id2label = {i: l for l, i in label2id.items()}\n",
    "df[\"label_id\"] = df[\"label\"].map(label2id)\n",
    "\n",
    "print(\"üß© Labels:\", label2id)\n",
    "print(\"üìä Dataset size:\", len(df))\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.15, stratify=df[\"label_id\"], random_state=42\n",
    ")\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "val_ds = Dataset.from_pandas(val_df)\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"statement\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True)\n",
    "val_ds = val_ds.map(tokenize, batched=True)\n",
    "\n",
    "# Rename label column to \"labels\" (so Trainer recognizes it)\n",
    "train_ds = train_ds.rename_column(\"label_id\", \"labels\")\n",
    "val_ds = val_ds.rename_column(\"label_id\", \"labels\")\n",
    "\n",
    "train_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# ============================================================\n",
    "# 3Ô∏è‚É£ Compute class weights\n",
    "# ============================================================\n",
    "class_counts = train_df[\"label_id\"].value_counts().sort_index().values\n",
    "weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)\n",
    "weights = weights / weights.sum() * len(class_counts)\n",
    "print(\"‚öñÔ∏è Class Weights:\", weights.tolist())\n",
    "\n",
    "# ============================================================\n",
    "# 4Ô∏è‚É£ Load model\n",
    "# ============================================================\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 5Ô∏è‚É£ Metrics and training args\n",
    "# ============================================================\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    return {\"accuracy\": acc, \"f1_macro\": f1}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/kaggle/working/mental_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir=\"/kaggle/working/logs\",\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.1,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 6Ô∏è‚É£ Trainer + EarlyStopping\n",
    "# ============================================================\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 7Ô∏è‚É£ Train\n",
    "# ============================================================\n",
    "trainer.train()\n",
    "\n",
    "# ============================================================\n",
    "# 8Ô∏è‚É£ Evaluate\n",
    "# ============================================================\n",
    "preds = trainer.predict(val_ds)\n",
    "pred_labels = np.argmax(preds.predictions, axis=1)\n",
    "print(\"\\nüìã Classification Report:\\n\")\n",
    "print(classification_report(val_df[\"label_id\"], pred_labels, target_names=labels))\n",
    "\n",
    "# ============================================================\n",
    "# 9Ô∏è‚É£ Save\n",
    "# ============================================================\n",
    "save_path = \"/kaggle/working/mentalwell_model_final\"\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "print(f\"\\n‚úÖ Model saved to: {save_path}\")\n",
    "\n",
    "# ============================================================\n",
    "# üîü Test Prediction\n",
    "# ============================================================\n",
    "from transformers import pipeline\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=save_path, tokenizer=save_path, return_all_scores=True)\n",
    "\n",
    "examples = [\n",
    "    \"I feel completely worthless and tired.\",\n",
    "    \"I am doing okay, just a little stressed.\",\n",
    "    \"I'm so happy I talked to my therapist today!\",\n",
    "]\n",
    "\n",
    "for text in examples:\n",
    "    preds = clf(text)\n",
    "    print(f\"\\nüß† Text: {text}\")\n",
    "    for e in preds[0]:\n",
    "        print(f\"  {e['label']}: {e['score']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T13:36:25.855448Z",
     "iopub.status.busy": "2025-11-11T13:36:25.854729Z",
     "iopub.status.idle": "2025-11-11T13:36:44.412569Z",
     "shell.execute_reply": "2025-11-11T13:36:44.411640Z",
     "shell.execute_reply.started": "2025-11-11T13:36:25.855417Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.3.4 which is incompatible.\n",
      "s3fs 2025.3.0 requires fsspec==2025.3.0.*, but you have fsspec 2025.10.0 which is incompatible.\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.2 which is incompatible.\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "ibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.1.0 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.9.0 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\n",
      "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.0 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\n",
      "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.9.0 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\n",
      "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† I feel completely worthless and tired.\n",
      "  anxiety: 0.005\n",
      "  bipolar: 0.001\n",
      "  depression: 0.590\n",
      "  normal: 0.051\n",
      "  personality disorder: 0.002\n",
      "  stress: 0.003\n",
      "  suicidal: 0.348\n",
      "\n",
      "üß† I'm so happy I talked to my therapist today!\n",
      "  anxiety: 0.030\n",
      "  bipolar: 0.403\n",
      "  depression: 0.073\n",
      "  normal: 0.436\n",
      "  personality disorder: 0.043\n",
      "  stress: 0.007\n",
      "  suicidal: 0.009\n",
      "\n",
      "üß† Why do I feel like I have no control over anything\n",
      "  anxiety: 0.071\n",
      "  bipolar: 0.004\n",
      "  depression: 0.771\n",
      "  normal: 0.009\n",
      "  personality disorder: 0.004\n",
      "  stress: 0.010\n",
      "  suicidal: 0.130\n",
      "\n",
      "üß† I want to kill myself\n",
      "  anxiety: 0.001\n",
      "  bipolar: 0.000\n",
      "  depression: 0.088\n",
      "  normal: 0.002\n",
      "  personality disorder: 0.000\n",
      "  stress: 0.000\n",
      "  suicidal: 0.909\n",
      "\n",
      "üß† Things are so stressful. I feel so restless\n",
      "  anxiety: 0.997\n",
      "  bipolar: 0.000\n",
      "  depression: 0.001\n",
      "  normal: 0.000\n",
      "  personality disorder: 0.000\n",
      "  stress: 0.001\n",
      "  suicidal: 0.000\n"
     ]
    }
   ],
   "source": [
    "!pip install -q --force-reinstall transformers==4.44.2 safetensors==0.4.5\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "model_dir = \"/kaggle/working/mentalwell_model_final\"\n",
    "\n",
    "# Load model + tokenizer automatically\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "# Build inference pipeline\n",
    "clf = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, return_all_scores=True)\n",
    "\n",
    "# Try a few examples\n",
    "texts = [\n",
    "    \"I feel completely worthless and tired.\",\n",
    "    \"I'm so happy I talked to my therapist today!\",\n",
    "    \"Why do I feel like I have no control over anything\",\n",
    "    \"I want to kill myself\",\n",
    "    \"Things are so stressful. I feel so restless\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    preds = clf(text)[0]\n",
    "    print(f\"\\nüß† {text}\")\n",
    "    for p in preds:\n",
    "        print(f\"  {p['label']}: {p['score']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T13:38:56.171860Z",
     "iopub.status.busy": "2025-11-11T13:38:56.171163Z",
     "iopub.status.idle": "2025-11-11T13:39:10.436623Z",
     "shell.execute_reply": "2025-11-11T13:39:10.435607Z",
     "shell.execute_reply.started": "2025-11-11T13:38:56.171831Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: mentalwell_model_final/ (stored 0%)\n",
      "  adding: mentalwell_model_final/vocab.txt (deflated 53%)\n",
      "  adding: mentalwell_model_final/tokenizer.json (deflated 71%)\n",
      "  adding: mentalwell_model_final/config.json (deflated 50%)\n",
      "  adding: mentalwell_model_final/model.safetensors"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (deflated 8%)\n",
      "  adding: mentalwell_model_final/tokenizer_config.json (deflated 75%)\n",
      "  adding: mentalwell_model_final/special_tokens_map.json (deflated 42%)\n"
     ]
    }
   ],
   "source": [
    "!cd /kaggle/working && zip -r mentalwell_model_final.zip mentalwell_model_final\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5338273,
     "sourceId": 8870083,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
