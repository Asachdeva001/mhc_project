{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8870083,"sourceType":"datasetVersion","datasetId":5338273}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q --upgrade transformers datasets accelerate scikit-learn torch\n\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    Trainer,\n    TrainingArguments,\n)\nfrom transformers.trainer_callback import EarlyStoppingCallback\nfrom torch import nn\nimport os, warnings\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ============================================================\n# 1Ô∏è‚É£ Custom Weighted Trainer\n# ============================================================\n\nclass WeightedTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n        \"\"\"\n        FINAL version:\n        - Handles num_items_in_batch\n        - Works with DataParallel or DDP\n        - Supports both 'labels' and 'label_id'\n        \"\"\"\n        # Extract labels safely\n        labels = inputs.pop(\"labels\", None)\n        if labels is None:\n            labels = inputs.pop(\"label_id\", None)\n\n        # Drop any unwanted Trainer args\n        for key in [\"num_items_in_batch\", \"loss_reduction\"]:\n            inputs.pop(key, None)\n            kwargs.pop(key, None)\n\n        # Forward pass\n        outputs = model(**inputs)\n        logits = outputs.get(\"logits\")\n\n        # ‚úÖ Handle both model and DataParallel wrapper\n        actual_model = model.module if hasattr(model, \"module\") else model\n\n        # ‚úÖ Correct device + config\n        device = next(model.parameters()).device\n        num_labels = actual_model.config.num_labels\n\n        # Weighted loss on correct device\n        loss_fct = nn.CrossEntropyLoss(weight=weights.to(device))\n        loss = loss_fct(\n            logits.view(-1, num_labels),\n            labels.view(-1)\n        )\n\n        return (loss, outputs) if return_outputs else loss\n\n\n# ============================================================\n# 2Ô∏è‚É£ Load and prepare dataset\n# ============================================================\ndf = pd.read_csv(\"/kaggle/input/sentiment-analysis-for-mental-health/Combined Data.csv\")\n\ndf = df.dropna(subset=[\"statement\", \"status\"])\ndf[\"label\"] = df[\"status\"].str.lower().str.strip()\n\nlabels = sorted(df[\"label\"].unique())\nlabel2id = {l: i for i, l in enumerate(labels)}\nid2label = {i: l for l, i in label2id.items()}\ndf[\"label_id\"] = df[\"label\"].map(label2id)\n\nprint(\"üß© Labels:\", label2id)\nprint(\"üìä Dataset size:\", len(df))\n\ntrain_df, val_df = train_test_split(\n    df, test_size=0.15, stratify=df[\"label_id\"], random_state=42\n)\n\ntrain_ds = Dataset.from_pandas(train_df)\nval_ds = Dataset.from_pandas(val_df)\n\nmodel_name = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef tokenize(batch):\n    return tokenizer(batch[\"statement\"], padding=\"max_length\", truncation=True, max_length=128)\n\ntrain_ds = train_ds.map(tokenize, batched=True)\nval_ds = val_ds.map(tokenize, batched=True)\n\n# Rename label column to \"labels\" (so Trainer recognizes it)\ntrain_ds = train_ds.rename_column(\"label_id\", \"labels\")\nval_ds = val_ds.rename_column(\"label_id\", \"labels\")\n\ntrain_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\nval_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n\n# ============================================================\n# 3Ô∏è‚É£ Compute class weights\n# ============================================================\nclass_counts = train_df[\"label_id\"].value_counts().sort_index().values\nweights = 1.0 / torch.tensor(class_counts, dtype=torch.float)\nweights = weights / weights.sum() * len(class_counts)\nprint(\"‚öñÔ∏è Class Weights:\", weights.tolist())\n\n# ============================================================\n# 4Ô∏è‚É£ Load model\n# ============================================================\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=len(labels),\n    id2label=id2label,\n    label2id=label2id,\n)\n\n# ============================================================\n# 5Ô∏è‚É£ Metrics and training args\n# ============================================================\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = np.argmax(pred.predictions, axis=1)\n    acc = accuracy_score(labels, preds)\n    f1 = f1_score(labels, preds, average=\"macro\")\n    return {\"accuracy\": acc, \"f1_macro\": f1}\n\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/mental_model\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=4,\n    weight_decay=0.01,\n    load_best_model_at_end=True,\n    logging_dir=\"/kaggle/working/logs\",\n    fp16=True,\n    warmup_ratio=0.1,\n    metric_for_best_model=\"f1_macro\",\n    greater_is_better=True,\n    save_total_limit=2,\n)\n\n# ============================================================\n# 6Ô∏è‚É£ Trainer + EarlyStopping\n# ============================================================\ntrainer = WeightedTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=val_ds,\n    processing_class=tokenizer,\n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n)\n\n# ============================================================\n# 7Ô∏è‚É£ Train\n# ============================================================\ntrainer.train()\n\n# ============================================================\n# 8Ô∏è‚É£ Evaluate\n# ============================================================\npreds = trainer.predict(val_ds)\npred_labels = np.argmax(preds.predictions, axis=1)\nprint(\"\\nüìã Classification Report:\\n\")\nprint(classification_report(val_df[\"label_id\"], pred_labels, target_names=labels))\n\n# ============================================================\n# 9Ô∏è‚É£ Save\n# ============================================================\nsave_path = \"/kaggle/working/mentalwell_model_final\"\nmodel.save_pretrained(save_path)\ntokenizer.save_pretrained(save_path)\nprint(f\"\\n‚úÖ Model saved to: {save_path}\")\n\n# ============================================================\n# üîü Test Prediction\n# ============================================================\nfrom transformers import pipeline\n\nclf = pipeline(\"text-classification\", model=save_path, tokenizer=save_path, return_all_scores=True)\n\nexamples = [\n    \"I feel completely worthless and tired.\",\n    \"I am doing okay, just a little stressed.\",\n    \"I'm so happy I talked to my therapist today!\",\n]\n\nfor text in examples:\n    preds = clf(text)\n    print(f\"\\nüß† Text: {text}\")\n    for e in preds[0]:\n        print(f\"  {e['label']}: {e['score']:.3f}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T13:04:18.445678Z","iopub.execute_input":"2025-11-11T13:04:18.445977Z","iopub.status.idle":"2025-11-11T13:30:28.026725Z","shell.execute_reply.started":"2025-11-11T13:04:18.445957Z","shell.execute_reply":"2025-11-11T13:30:28.025556Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"üß© Labels: {'anxiety': 0, 'bipolar': 1, 'depression': 2, 'normal': 3, 'personality disorder': 4, 'stress': 5, 'suicidal': 6}\nüìä Dataset size: 52681\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/44778 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64c8d1c0f64147e2b3e90968f7888add"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7903 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc814b414cd747b39b1187855d83df3d"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"‚öñÔ∏è Class Weights: [0.8456476330757141, 1.1699321269989014, 0.21087905764579773, 0.1987646520137787, 3.014235496520996, 1.2555887699127197, 0.304952472448349]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5600' max='5600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5600/5600 25:27, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.730000</td>\n      <td>0.598715</td>\n      <td>0.764773</td>\n      <td>0.742266</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.489800</td>\n      <td>0.533104</td>\n      <td>0.811211</td>\n      <td>0.790274</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.347500</td>\n      <td>0.549305</td>\n      <td>0.812603</td>\n      <td>0.798602</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.255300</td>\n      <td>0.548064</td>\n      <td>0.823864</td>\n      <td>0.810938</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nüìã Classification Report:\n\n                      precision    recall  f1-score   support\n\n             anxiety       0.87      0.88      0.87       576\n             bipolar       0.83      0.88      0.86       417\n          depression       0.81      0.72      0.76      2311\n              normal       0.97      0.93      0.95      2452\npersonality disorder       0.71      0.78      0.74       161\n              stress       0.71      0.84      0.77       388\n            suicidal       0.68      0.77      0.72      1598\n\n            accuracy                           0.82      7903\n           macro avg       0.80      0.83      0.81      7903\n        weighted avg       0.83      0.82      0.83      7903\n\n\n‚úÖ Model saved to: /kaggle/working/mentalwell_model_final\nüö® `do_pad` is part of DefaultFastImageProcessorKwargs, but not documented. Make sure to add it to the docstring of the function in /usr/local/lib/python3.11/dist-packages/transformers/image_processing_utils_fast.py.\nüö® `pad_size` is part of DefaultFastImageProcessorKwargs, but not documented. Make sure to add it to the docstring of the function in /usr/local/lib/python3.11/dist-packages/transformers/image_processing_utils_fast.py.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/145110175.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;31m# üîü Test Prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;31m# ============================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text-classification\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_all_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2152\u001b[0m     \u001b[0mis_dummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2154\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"_from_config\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"is_dummy\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mro\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"call\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0mmodule_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2183\u001b[0m         \u001b[0mimport_structure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIMPORT_STRUCTURE_T\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2184\u001b[0;31m         \u001b[0mmodule_spec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmachinery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleSpec\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2185\u001b[0m         \u001b[0mextra_objects\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2186\u001b[0m         \u001b[0mexplicit_import_shortcut\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2180\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2181\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2182\u001b[0;31m         \u001b[0mmodule_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2183\u001b[0m         \u001b[0mimport_structure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIMPORT_STRUCTURE_T\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2184\u001b[0m         \u001b[0mmodule_spec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmachinery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleSpec\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_processing_auto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIMAGE_PROCESSOR_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoImageProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_auto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForDepthEstimation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForImageToImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessing_auto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPROCESSOR_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_auto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTOKENIZER_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProcessorMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/processing_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mtokenization_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFEATURE_EXTRACTOR_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPROCESSOR_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVIDEO_PROCESSOR_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mvideo_processing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseVideoProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mauto_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LazyAutoMapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m from .configuration_auto import (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/video_processing_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequires\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m from .video_utils import (\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mVideoInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mVideoMetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'make_batched_metadata' from 'transformers.video_utils' (/usr/local/lib/python3.11/dist-packages/transformers/video_utils.py)"],"ename":"ImportError","evalue":"cannot import name 'make_batched_metadata' from 'transformers.video_utils' (/usr/local/lib/python3.11/dist-packages/transformers/video_utils.py)","output_type":"error"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q --force-reinstall transformers==4.44.2 safetensors==0.4.5\n\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n\nmodel_dir = \"/kaggle/working/mentalwell_model_final\"\n\n# Load model + tokenizer automatically\ntokenizer = AutoTokenizer.from_pretrained(model_dir)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_dir)\n\n# Build inference pipeline\nclf = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, return_all_scores=True)\n\n# Try a few examples\ntexts = [\n    \"I feel completely worthless and tired.\",\n    \"I'm so happy I talked to my therapist today!\",\n    \"Why do I feel like I have no control over anything\",\n    \"I want to kill myself\",\n    \"Things are so stressful. I feel so restless\"\n]\n\nfor text in texts:\n    preds = clf(text)[0]\n    print(f\"\\nüß† {text}\")\n    for p in preds:\n        print(f\"  {p['label']}: {p['score']:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T13:36:25.854729Z","iopub.execute_input":"2025-11-11T13:36:25.855448Z","iopub.status.idle":"2025-11-11T13:36:44.412569Z","shell.execute_reply.started":"2025-11-11T13:36:25.855417Z","shell.execute_reply":"2025-11-11T13:36:44.411640Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nnumba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.3.4 which is incompatible.\ns3fs 2025.3.0 requires fsspec==2025.3.0.*, but you have fsspec 2025.10.0 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.2 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nsklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.1.0 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.9.0 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\ngoogle-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\ntorchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.9.0 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\njupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"name":"stdout","text":"\nüß† I feel completely worthless and tired.\n  anxiety: 0.005\n  bipolar: 0.001\n  depression: 0.590\n  normal: 0.051\n  personality disorder: 0.002\n  stress: 0.003\n  suicidal: 0.348\n\nüß† I'm so happy I talked to my therapist today!\n  anxiety: 0.030\n  bipolar: 0.403\n  depression: 0.073\n  normal: 0.436\n  personality disorder: 0.043\n  stress: 0.007\n  suicidal: 0.009\n\nüß† Why do I feel like I have no control over anything\n  anxiety: 0.071\n  bipolar: 0.004\n  depression: 0.771\n  normal: 0.009\n  personality disorder: 0.004\n  stress: 0.010\n  suicidal: 0.130\n\nüß† I want to kill myself\n  anxiety: 0.001\n  bipolar: 0.000\n  depression: 0.088\n  normal: 0.002\n  personality disorder: 0.000\n  stress: 0.000\n  suicidal: 0.909\n\nüß† Things are so stressful. I feel so restless\n  anxiety: 0.997\n  bipolar: 0.000\n  depression: 0.001\n  normal: 0.000\n  personality disorder: 0.000\n  stress: 0.001\n  suicidal: 0.000\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"!cd /kaggle/working && zip -r mentalwell_model_final.zip mentalwell_model_final\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T13:38:56.171163Z","iopub.execute_input":"2025-11-11T13:38:56.171860Z","iopub.status.idle":"2025-11-11T13:39:10.436623Z","shell.execute_reply.started":"2025-11-11T13:38:56.171831Z","shell.execute_reply":"2025-11-11T13:39:10.435607Z"}},"outputs":[{"name":"stdout","text":"  adding: mentalwell_model_final/ (stored 0%)\n  adding: mentalwell_model_final/vocab.txt (deflated 53%)\n  adding: mentalwell_model_final/tokenizer.json (deflated 71%)\n  adding: mentalwell_model_final/config.json (deflated 50%)\n  adding: mentalwell_model_final/model.safetensors","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 8%)\n  adding: mentalwell_model_final/tokenizer_config.json (deflated 75%)\n  adding: mentalwell_model_final/special_tokens_map.json (deflated 42%)\n","output_type":"stream"}],"execution_count":29}]}